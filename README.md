# LLMDeploymentLocally
Deploying LLM Models in Local Machine

Youtube Link: https://youtu.be/auXQ9QT6_z4

2 Models in the REPO 

1 is Ollama LLM3 Language model
run Ollama file and test the script which is connected to ollama server in order run script you need to have Ollama and python install in your machine
>Ollama serve # to serve the server
you can also use terminal to run Ollama using terminal command
>Ollama run


 2 GPT2 Language Model

In order to use GPT-2 Language model
Run download_gpt2.py file it will create Transformer and torch and GPT2 model in your local machine with which
in next step run app_gpt2.py file where you can test the response and can fed the input accordingly
